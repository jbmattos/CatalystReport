{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7015c615-5a7e-41ef-ba1e-4a78aca35018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from catalyst_votingresults import CatalystVotingResults\n",
    "from catalyst_assessments import CatalystAssessments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c03e80",
   "metadata": {},
   "source": [
    "# =================\n",
    "# LOAD DATA\n",
    "## DIRECTLY FILE_PATH INFO\n",
    "# ================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408b58ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LOAD XLSX DATA FROM ALL FUNDS INTO < pd.ExcelFile >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13181904",
   "metadata": {},
   "source": [
    "### ASSESSMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "860d6a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funds loaded: ['f3', 'f4', 'f5', 'f6', 'f7', 'f8']\n"
     ]
    }
   ],
   "source": [
    "PATH = \"/home/julianabmattos/GitRepositories/CatalystReport/data/datafiles_assessments/\"\n",
    "TYPE = \"ASSESSMENTS\"\n",
    "DEFAULT_ASSESSMENTS_FEATS = ['CA','PROPOSAL_TITLE','CA_RATING','QA_STATUS','REASON','QA_CLASS']\n",
    "FUNDS_FILES = {      \n",
    "    \"f3\": PATH+\"Community Aggregated - Review of Reviewers v3.xlsx\",\n",
    "    \"f4\": PATH+\"Final_vCA Aggregated - fund4.xlsx\",\n",
    "    \"f5\": PATH+\"vCA Aggregated - Fund 5.xlsx\",\n",
    "    \"f6\": PATH+\"vCA Aggregated - Fund 6.xlsx\",\n",
    "    \"f7\": PATH+\"vCA Aggregated - Fund 7.xlsx\",\n",
    "    \"f8\": PATH+\"vCA Aggregated - Fund 8 (Final MVP candidate).xlsx\"\n",
    "}\n",
    "dbs_from_xls = {}\n",
    "for f, file in FUNDS_FILES.items():\n",
    "    dbs_from_xls[f] = pd.ExcelFile(file)\n",
    "print('Funds loaded: {}'.format(list(dbs_from_xls.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dedaca1",
   "metadata": {},
   "source": [
    "### VOTING RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe18e4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"/home/julianabmattos/GitRepositories/CatalystReport/data/datafiles_votingresults/\"\n",
    "# TYPE = \"VOTING RESULTS\"\n",
    "# funds = ['f3','f4','f5','f6','f7','f8']\n",
    "# files = [\"Fund3 Voting results.xlsx\",\n",
    "#          \"Fund4 Voting results.xlsx\",\n",
    "#          \"Fund5 Voting results.xlsx\",\n",
    "#          \"Fund6 Voting results.xlsx\",\n",
    "#          \"Fund7 Voting results.xlsx\",\n",
    "#          \"Fund8 Voting results.xlsx\"]\n",
    "# dbs_from_xls = {}\n",
    "# for f, file in zip(funds, files):\n",
    "#     dbs_from_xls[f] = pd.ExcelFile(path+file)\n",
    "# print('Funds loaded: {}'.format(list(dbs_from_xls.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c15d43b-3208-4044-aa9c-94eccc757f80",
   "metadata": {},
   "source": [
    "## SHEETS NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ff280b-bf4a-4178-9d16-95cc746ee42e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sheets = {}\n",
    "print(\"Data source: {}\".format(TYPE))\n",
    "print('Sheets by fund:\\n')\n",
    "for f, xls in dbs_from_xls.items():\n",
    "    sheets[f] = list(dbs_from_xls[f].sheet_names)\n",
    "    print(\"{}: {}\".format(f, sheets[f]))\n",
    "    print('#',len(sheets[f]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babe1866",
   "metadata": {},
   "source": [
    "# ========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f114bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'f7'\n",
    "xlsx_obj = dbs_from_xls[f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12bff47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = xlsx_obj.parse(sheet_name='vCA Aggregated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1103dafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fund 3 analysis\n",
    "cols = ['Outcome','Rene M', 'Łukasz K',\n",
    "       'Robert T', 'Olexiy M', 'Filip B', 'Michael P', 'Cryptostig',\n",
    "       '2072 [ANFRA]', 'Rodrigo P', 'RescuedCookie22', 'CryptoPrime',\n",
    "       'Steve A', 'Matias P', 'Jaime S', 'Ilija', 'Anthony', 'Greg P',\n",
    "       'James A', 'Thiago', 'Danny R']\n",
    "c = list(set(cols) - set(['Outcome']))\n",
    "\n",
    "for i in df.index:\n",
    "    print()\n",
    "    print('>> ASSESSMENT: ',i)\n",
    "    print('Outcome: ', df.loc[i, 'Outcome'])\n",
    "    print('Value counts:')\n",
    "    print(df.loc[i, c].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fc0bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = 'f3'\n",
    "# xlsx_obj = dbs_from_xls[f]\n",
    "\n",
    "# valid = xlsx_obj.parse(sheet_name='Proposals')\n",
    "# val_columns = {\n",
    "#     'Idea Title' : 'PROPOSAL_TITLE',\n",
    "#     'Assessor': 'CA'\n",
    "# }\n",
    "# df_valid = valid[val_columns.keys()].rename(columns=val_columns)\n",
    "# df_valid['CA_RATING'] = np.nan\n",
    "# df_valid['QA_CLASS'] = np.nan\n",
    "# df_valid['REASON'] = valid['Outcome'].replace({np.nan:\"NOT_VOTTED\"})\n",
    "# df_valid['QA_STATUS'] = df_valid['REASON'].map(lambda v: 'Excluded' if v=='UNJUSTIFIED' else 'Valid')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a79ff07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROPOSAL_TITLE</th>\n",
       "      <th>CA</th>\n",
       "      <th>CA_RATING</th>\n",
       "      <th>QA_CLASS</th>\n",
       "      <th>REASON</th>\n",
       "      <th>QA_STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a better catalyst</td>\n",
       "      <td>z_assessor_103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DISPUTED</td>\n",
       "      <td>Valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a better catalyst</td>\n",
       "      <td>z_assessor_104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JUSTIFIED</td>\n",
       "      <td>Valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a better catalyst</td>\n",
       "      <td>z_assessor_116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT_VOTTED</td>\n",
       "      <td>Valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a better catalyst</td>\n",
       "      <td>z_assessor_117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT_VOTTED</td>\n",
       "      <td>Valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a better catalyst</td>\n",
       "      <td>z_assessor_118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JUSTIFIED</td>\n",
       "      <td>Valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9571</th>\n",
       "      <td>Write Dapps as continuous workflows</td>\n",
       "      <td>z_assessor_45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT_VOTTED</td>\n",
       "      <td>Valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9572</th>\n",
       "      <td>Write Dapps as continuous workflows</td>\n",
       "      <td>z_assessor_49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JUSTIFIED</td>\n",
       "      <td>Valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9573</th>\n",
       "      <td>Write Dapps as continuous workflows</td>\n",
       "      <td>z_assessor_53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT_VOTTED</td>\n",
       "      <td>Valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9574</th>\n",
       "      <td>Write Dapps as continuous workflows</td>\n",
       "      <td>z_assessor_59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JUSTIFIED</td>\n",
       "      <td>Valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9575</th>\n",
       "      <td>Write Dapps as continuous workflows</td>\n",
       "      <td>z_assessor_62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT_VOTTED</td>\n",
       "      <td>Valid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9576 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           PROPOSAL_TITLE              CA  CA_RATING  \\\n",
       "0                       a better catalyst  z_assessor_103        NaN   \n",
       "1                       a better catalyst  z_assessor_104        NaN   \n",
       "2                       a better catalyst  z_assessor_116        NaN   \n",
       "3                       a better catalyst  z_assessor_117        NaN   \n",
       "4                       a better catalyst  z_assessor_118        NaN   \n",
       "...                                   ...             ...        ...   \n",
       "9571  Write Dapps as continuous workflows   z_assessor_45        NaN   \n",
       "9572  Write Dapps as continuous workflows   z_assessor_49        NaN   \n",
       "9573  Write Dapps as continuous workflows   z_assessor_53        NaN   \n",
       "9574  Write Dapps as continuous workflows   z_assessor_59        NaN   \n",
       "9575  Write Dapps as continuous workflows   z_assessor_62        NaN   \n",
       "\n",
       "      QA_CLASS      REASON QA_STATUS  \n",
       "0          NaN    DISPUTED     Valid  \n",
       "1          NaN   JUSTIFIED     Valid  \n",
       "2          NaN  NOT_VOTTED     Valid  \n",
       "3          NaN  NOT_VOTTED     Valid  \n",
       "4          NaN   JUSTIFIED     Valid  \n",
       "...        ...         ...       ...  \n",
       "9571       NaN  NOT_VOTTED     Valid  \n",
       "9572       NaN   JUSTIFIED     Valid  \n",
       "9573       NaN  NOT_VOTTED     Valid  \n",
       "9574       NaN   JUSTIFIED     Valid  \n",
       "9575       NaN  NOT_VOTTED     Valid  \n",
       "\n",
       "[9576 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2270b4e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Valid', 'Excluded'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.QA_STATUS.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b30ba2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DISPUTED', 'JUSTIFIED', 'NOT_VOTTED', 'UNJUSTIFIED'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.REASON.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49d80f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e5afba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db00a84e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee1cc60d",
   "metadata": {},
   "source": [
    "# ====================\n",
    "#    ASSESSMENTS DEV\n",
    "# ===================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd6448a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9576 entries, 0 to 9575\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   CA              9576 non-null   object \n",
      " 1   PROPOSAL_TITLE  9576 non-null   object \n",
      " 2   CA_RATING       0 non-null      float64\n",
      " 3   QA_STATUS       9576 non-null   object \n",
      " 4   REASON          9576 non-null   object \n",
      " 5   QA_CLASS        0 non-null      float64\n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 449.0+ KB\n"
     ]
    }
   ],
   "source": [
    "f = 'f3'\n",
    "df = CatalystAssessments(f)\n",
    "df.assessments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5ae3edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7141 entries, 0 to 7140\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   CA              7141 non-null   object \n",
      " 1   PROPOSAL_TITLE  7141 non-null   object \n",
      " 2   CA_RATING       7141 non-null   float64\n",
      " 3   QA_STATUS       7141 non-null   object \n",
      " 4   REASON          7141 non-null   object \n",
      " 5   QA_CLASS        0 non-null      float64\n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 334.9+ KB\n"
     ]
    }
   ],
   "source": [
    "f = 'f4'\n",
    "df = CatalystAssessments(f)\n",
    "df.assessments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6955c448",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8433 entries, 0 to 8432\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   CA              8433 non-null   object \n",
      " 1   PROPOSAL_TITLE  8433 non-null   object \n",
      " 2   CA_RATING       8433 non-null   int64  \n",
      " 3   QA_STATUS       8433 non-null   object \n",
      " 4   REASON          8433 non-null   object \n",
      " 5   QA_CLASS        0 non-null      float64\n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 395.4+ KB\n"
     ]
    }
   ],
   "source": [
    "f = 'f5'\n",
    "df = CatalystAssessments(f)\n",
    "df.assessments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc928449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5172 entries, 0 to 5171\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   CA              5172 non-null   object \n",
      " 1   PROPOSAL_TITLE  5172 non-null   object \n",
      " 2   CA_RATING       5172 non-null   float64\n",
      " 3   QA_STATUS       5172 non-null   object \n",
      " 4   REASON          5172 non-null   object \n",
      " 5   QA_CLASS        4118 non-null   object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 242.6+ KB\n"
     ]
    }
   ],
   "source": [
    "f = 'f6'\n",
    "df = CatalystAssessments(f)\n",
    "df.assessments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cff6d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9393 entries, 0 to 9392\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   CA              9393 non-null   object \n",
      " 1   PROPOSAL_TITLE  9393 non-null   object \n",
      " 2   CA_RATING       9393 non-null   float64\n",
      " 3   QA_STATUS       9393 non-null   object \n",
      " 4   REASON          9393 non-null   object \n",
      " 5   QA_CLASS        9161 non-null   object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 440.4+ KB\n"
     ]
    }
   ],
   "source": [
    "f = 'f7'\n",
    "df = CatalystAssessments(f)\n",
    "df.assessments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9235199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QA_STATUS: ['Valid' 'Excluded']\n",
      "REASON: ['Valid' '<150 char' 'Blank']\n",
      "QA_CLASS: ['Good' 'Excelent' 'Filtered Out' nan]\n"
     ]
    }
   ],
   "source": [
    "print('QA_STATUS: {}'.format(df.assessments.QA_STATUS.unique()))\n",
    "print('REASON: {}'.format(df.assessments.REASON.unique()))\n",
    "print('QA_CLASS: {}'.format(df.assessments.QA_CLASS.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1530485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11017 entries, 0 to 11016\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   CA              11017 non-null  object \n",
      " 1   PROPOSAL_TITLE  11017 non-null  object \n",
      " 2   CA_RATING       11017 non-null  float64\n",
      " 3   QA_STATUS       11017 non-null  object \n",
      " 4   REASON          11017 non-null  object \n",
      " 5   QA_CLASS        11017 non-null  object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 516.5+ KB\n"
     ]
    }
   ],
   "source": [
    "f = 'f8'\n",
    "df = CatalystAssessments(f)\n",
    "df.assessments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59392670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CA</th>\n",
       "      <th>PROPOSAL_TITLE</th>\n",
       "      <th>CA_RATING</th>\n",
       "      <th>QA_STATUS</th>\n",
       "      <th>REASON</th>\n",
       "      <th>QA_CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>z_assessor_1003</td>\n",
       "      <td>American USDC think tank</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>z_assessor_1003</td>\n",
       "      <td>Three.js for 3D-Webaverse games</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Excelent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>z_assessor_1003</td>\n",
       "      <td>P.I.E for Gamers-On-Chained</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                CA                   PROPOSAL_TITLE  CA_RATING QA_STATUS  \\\n",
       "0  z_assessor_1003         American USDC think tank   2.666667     Valid   \n",
       "1  z_assessor_1003  Three.js for 3D-Webaverse games   2.000000     Valid   \n",
       "2  z_assessor_1003      P.I.E for Gamers-On-Chained   3.666667     Valid   \n",
       "\n",
       "  REASON  QA_CLASS  \n",
       "0  Valid      Good  \n",
       "1  Valid  Excelent  \n",
       "2  Valid      Good  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.assessments.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1d1c30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QA_STATUS: ['Valid' 'Excluded']\n",
      "REASON: ['Valid' '<150 char']\n",
      "QA_CLASS: ['Good' 'Excelent' 'Filtered Out']\n"
     ]
    }
   ],
   "source": [
    "print('QA_STATUS: {}'.format(df.assessments.QA_STATUS.unique()))\n",
    "print('REASON: {}'.format(df.assessments.REASON.unique()))\n",
    "print('QA_CLASS: {}'.format(df.assessments.QA_CLASS.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026ca0f8",
   "metadata": {},
   "source": [
    "# ====================\n",
    "# VOTING RESULTS DEV\n",
    "# ===================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5b96e9-e22c-4c4e-acd7-72924613264b",
   "metadata": {},
   "source": [
    "# VALIDATION DATAFRAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0187e0a",
   "metadata": {},
   "source": [
    "## RAW VALIDATION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee51dcb-d0ad-474a-9b79-38e86e0c7aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xls = {}\n",
    "for fund in funds:\n",
    "\n",
    "    if 'validation' in sheets[f]:\n",
    "        df_valid = dbs_from_xls[f].parse(sheet_name='validation')\n",
    "    elif 'Validation' in sheets[f]:\n",
    "        df_valid = dbs_from_xls[f].parse(sheet_name='Validation')\n",
    "    else:\n",
    "        df_valid = None\n",
    "\n",
    "    print(\">> FUND: {}\".format(fund))\n",
    "    print('Challenges/sheets: {}'.format(list(sheets[f])))\n",
    "    print('#Challenges/sheets: {}'.format(len(list(sheets[f]))))\n",
    "    print('Validation df:')\n",
    "    display(df_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f756ddee-98de-420d-8bf1-c03967fe71eb",
   "metadata": {},
   "source": [
    "## VALIDATION DF SETUP: CATALYST-RESULTS OBJECTS\n",
    "df format: pd.DataFrames.columns = [challanges, budget]\\\n",
    "**All formatted validation dfs from f3-f8 match the data online**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e25ca8-c120-4984-b69b-0f938aaad9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_COLS = ['challange', 'budget']\n",
    "def __default_setup(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    df.columns = VALIDATION_COLS\n",
    "    df.dropna(subset=['challange'],inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df['budget'] = df['budget'].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f194d6b-f298-40b4-afbe-5dcacd446b44",
   "metadata": {},
   "source": [
    "### FUND: F3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bca85c-783f-4ad4-a971-5b40a08369eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fund = 'f3'\n",
    "print('#Raw Challenges/sheets (validation/withdraws included): {}\\n'.format(len(list(sheets[fund]))))\n",
    "df = CatalystVotingResults(fund).validation.copy()\n",
    "\n",
    "# df = df.iloc[:-1].copy()\n",
    "# func_format = lambda s: s.split('(')[1].split(')')[0] if isinstance(s, str) else s\n",
    "# df.iloc[:,0] = df.iloc[:,0].map(func_format)\n",
    "# df = __default_setup(df)\n",
    "\n",
    "display(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f8a6d4-763f-4bfd-b2e1-97a27b717412",
   "metadata": {},
   "source": [
    "### FUND: F4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbcf853-de89-442e-a8ea-4eeea416d845",
   "metadata": {},
   "outputs": [],
   "source": [
    "fund = 'f4'\n",
    "print('#Raw Challenges/sheets (validation/withdraws included): {}\\n'.format(len(list(sheets[fund]))))\n",
    "df = CatalystVotingResults(fund).validation.copy()\n",
    "\n",
    "# func_format = lambda s: s.split('(')[1].split(')')[0] if isinstance(s, str) else s\n",
    "# df.iloc[9:16,0] = df.iloc[9:16,0].map(func_format)\n",
    "# df = __default_setup(df)\n",
    "\n",
    "display(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f681464-eca8-48be-98b3-a47fc53eb546",
   "metadata": {},
   "source": [
    "### FUND: F5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98107213-c3f6-408c-991c-a4b07b6db835",
   "metadata": {},
   "outputs": [],
   "source": [
    "fund = 'f5'\n",
    "print('#Raw Challenges/sheets (validation/withdraws included): {}\\n'.format(len(list(sheets[fund]))))\n",
    "df = CatalystVotingResults(fund).validation.copy()\n",
    "\n",
    "# func_format = lambda s: s.split('(')[1].split(')')[0] if isinstance(s, str) else s\n",
    "# df.iloc[9:18,0] = df.iloc[9:18,0].map(func_format)\n",
    "# df = __default_setup(df)\n",
    "\n",
    "display(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d83bac9-5658-429c-8ebc-82519860618b",
   "metadata": {},
   "source": [
    "### FUND: F6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee1d47a-feb0-4027-8a87-e5b6ebb97013",
   "metadata": {},
   "outputs": [],
   "source": [
    "fund = 'f6'\n",
    "print('#Raw Challenges/sheets (validation/withdraws included): {}\\n'.format(len(list(sheets[fund]))))\n",
    "df = get_catalyst_data(fund).validation.copy()\n",
    "\n",
    "# df = df.iloc[:-2].copy()\n",
    "# df.drop(columns='Fund size:', inplace=True)\n",
    "# df = __default_setup(df)\n",
    "\n",
    "display(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e4ea6e-3a1c-4380-9c8d-ac7877b4bfb3",
   "metadata": {},
   "source": [
    "### FUND: F7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4777f9d-4649-4d73-a8c8-bea3f2db9a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fund = 'f7'\n",
    "print('#Raw Challenges/sheets (validation/withdraws included): {}\\n'.format(len(list(sheets[fund]))))\n",
    "df = get_catalyst_data(fund).validation.copy()\n",
    "\n",
    "# df.drop(columns=['Fund size:','Unnamed: 3'],inplace=True)\n",
    "# df = __default_setup(df)\n",
    "\n",
    "display(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5419ebf-8d9d-4f1c-b524-71ffd0587a6f",
   "metadata": {},
   "source": [
    "### FUND: F8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6907d1f6-51f0-4fb7-a254-49214555833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fund = 'f8'\n",
    "print('#Raw Challenges/sheets (validation/withdraws included): {}\\n'.format(len(list(sheets[fund]))))\n",
    "df = get_catalyst_data(fund).validation.copy()\n",
    "\n",
    "# df.drop(columns=['Fund size:'],inplace=True)\n",
    "# df = __default_setup(df)\n",
    "\n",
    "display(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0aa287",
   "metadata": {},
   "source": [
    "### OVEFRVIEW ON CATALYST-RESULTS OBJS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35ee225",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_obj = {} # to store CatalystData objects\n",
    "for fund in funds:\n",
    "    cat_obj[fund] = get_catalyst_data(fund)\n",
    "    \n",
    "    print('\\nFUND: {}'.format(fund))\n",
    "    print(\"#CHALLANGES: {}\".format(len(list(cat_obj[fund].data.keys()))))\n",
    "    print(\"#CHALLANGES: {}\".format(list(cat_obj[fund].data.keys())))\n",
    "    print(\"VALIDATION: {}\".format(type(cat_obj[fund].validation)))\n",
    "    print(\"WITHDRAWALS: {}\".format(type(cat_obj[fund].withdrawals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ea7a31",
   "metadata": {},
   "source": [
    "# INPUT CHALLANGE NAME & BUDGET:\n",
    "## Identification of inconsistent Challenge's name between DataFrame-key and Validation\n",
    "Inconsistent names where inputed to a mapping dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499eb972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_budget(data):\n",
    "    print('\\n EXTRACTED BUDGETS:')\n",
    "    for ch in data.data.keys():\n",
    "        print('>> Challenge: {}'.format(ch))\n",
    "        try:\n",
    "            bud = data.validation.loc[data.validation.challenge==ch]['budget'].item()\n",
    "        except:\n",
    "            bud = np.nan\n",
    "        print('budget: ', bud)\n",
    "                          \n",
    "    display(data.validation)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b449cd22",
   "metadata": {},
   "source": [
    "### FUND: F3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f1916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fund = 'f3'\n",
    "data = cat_obj[fund]\n",
    "print(\"Data challenges: \", list(data.data.keys()))\n",
    "print(\"Validation challenges: {}\".format(list(data.validation.challenge.values)))\n",
    "\n",
    "check_budget(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b13e63b",
   "metadata": {},
   "source": [
    "### FUND: F4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd82f451",
   "metadata": {},
   "outputs": [],
   "source": [
    "fund = 'f4'\n",
    "data = cat_obj[fund]\n",
    "print(\"Data challanges: \", list(data.data.keys()))\n",
    "print(\"Validation challanges: {}\".format(list(data.validation.challenge.values)))\n",
    "\n",
    "check_budget(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b528fa6f",
   "metadata": {},
   "source": [
    "### FUND: F5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00916d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "fund = 'f5'\n",
    "data = cat_obj[fund]\n",
    "print(\"Data challanges: \", list(data.data.keys()))\n",
    "print(\"Validation challanges: {}\".format(list(data.validation.challenge.values)))\n",
    "\n",
    "check_budget(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c71acf",
   "metadata": {},
   "source": [
    "### FUND: F6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20139c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fund = 'f6'\n",
    "data = cat_obj[fund]\n",
    "print(\"Data challanges: \", list(data.data.keys()))\n",
    "print(\"Validation challanges: {}\".format(list(data.validation.challenge.values)))\n",
    "\n",
    "check_budget(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83984ed0",
   "metadata": {},
   "source": [
    "### FUND: F7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0074c2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fund = 'f7'\n",
    "data = cat_obj[fund]\n",
    "print(\"Data challanges: \", list(data.data.keys()))\n",
    "print(\"Validation challanges: {}\".format(list(data.validation.challenge.values)))\n",
    "\n",
    "check_budget(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9245691",
   "metadata": {},
   "source": [
    "### FUND: F8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee48526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fund = 'f8'\n",
    "data = cat_obj[fund]\n",
    "print(\"Data challanges: \", list(data.data.keys()))\n",
    "print(\"Validation challanges: {}\".format(list(data.validation.challenge.values)))\n",
    "\n",
    "check_budget(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0991cc",
   "metadata": {},
   "source": [
    "# CHALLENGE'S DATA\n",
    "Information analysis from CatalystData objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3551a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_COLS = ['Proposal', 'SCORE', 'YES', 'NO', 'Unique Yes', 'Unique No', 'Result','STATUS','REQUESTED $', 'challenge', 'Budget']\n",
    "CURRENCY_COLS = ['YES', 'NO', 'Result']\n",
    "def print_ch(fund):\n",
    "    print(\"#CHALLANGES: {}\".format(len(cat_obj[fund].data.keys())))\n",
    "    for ch, df in cat_obj[fund].data.items():\n",
    "        print('\\nCHALLANGE: {}'.format(ch))\n",
    "        print(\"columns: {}\".format(list(df.columns)))\n",
    "        print(\"Missing defaults: {}\".format(set(DEFAULT_COLS) - set(cat_obj[fund].data[ch].columns)))\n",
    "def view_currency_cols(fund):\n",
    "    for ch, df in cat_obj[fund].data.items():\n",
    "        print('>CHALLENGE: {}'.format(ch))\n",
    "        display(df[CURRENCY_COLS].head(3))\n",
    "def print_requested(fund):\n",
    "    for ch, df in cat_obj[fund].data.items():\n",
    "        print('>CHALLENGE: {}'.format(ch))\n",
    "        display(df['REQUESTED $'].head(3))\n",
    "def display_info(fund):\n",
    "    for ch, df in cat_obj[fund].data.items():\n",
    "        print('>CHALLENGE: {}'.format(ch))\n",
    "        display(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bc02be",
   "metadata": {},
   "source": [
    "## ALL CHALLENGES ALL FUNDS...\n",
    "### Identify necessary features formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b307b19",
   "metadata": {},
   "source": [
    "#### Currency features format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601ab281",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fund in funds:\n",
    "    print('\\n >> FUND: {}'.format(fund))\n",
    "    view_currency_cols(fund)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14828259",
   "metadata": {},
   "source": [
    "#### 'REQUESTED \\$' FEATURE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec170ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fund in funds:\n",
    "    print('\\n >> FUND: {}'.format(fund))\n",
    "    print_requested(fund)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1ac211",
   "metadata": {},
   "source": [
    "#### Columns vs Missing default-columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe37aaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for fund in funds:\n",
    "    print('\\n >> FUND: {}'.format(fund))\n",
    "    print_ch(fund)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248793df",
   "metadata": {},
   "source": [
    "#### DataFrame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb58d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fund in funds:\n",
    "    print('\\n >> FUND: {}'.format(fund))\n",
    "    display_info(fund)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fdb093",
   "metadata": {},
   "source": [
    "# RESULTS DATAFRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09324b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results():\n",
    "    for fund in funds:\n",
    "        print(\"\\n\\nFUND: {}\".format(fund))\n",
    "        display(cat_obj[fund].results.head(3))\n",
    "        print(cat_obj[fund].results.info())\n",
    "        print('\\n>> Unique challenges: {}'.format(list(cat_obj[fund].results.challenge.unique())))\n",
    "        print('# {}'.format(len(list(cat_obj[fund].results.challenge.unique()))))\n",
    "display_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da79a4ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f83178b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946b2afb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709116d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc474b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6346ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
